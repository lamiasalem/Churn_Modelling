{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import pandas as pd                  \n",
    "import numpy as np                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "\n",
    "dataset = pd.read_csv ('Churn_Modelling.csv' , sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>15643966</td>\n",
       "      <td>Goforth</td>\n",
       "      <td>616</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>15737452</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>15788218</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>549</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>15661507</td>\n",
       "      <td>Muldrow</td>\n",
       "      <td>587</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>15568982</td>\n",
       "      <td>Hao</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           1    15634602   Hargrave          619    France  Female   42   \n",
       "1           2    15647311       Hill          608     Spain  Female   41   \n",
       "2           3    15619304       Onio          502    France  Female   42   \n",
       "3           4    15701354       Boni          699    France  Female   39   \n",
       "4           5    15737888   Mitchell          850     Spain  Female   43   \n",
       "5           6    15574012        Chu          645     Spain    Male   44   \n",
       "6           7    15592531   Bartlett          822    France    Male   50   \n",
       "7           8    15656148     Obinna          376   Germany  Female   29   \n",
       "8           9    15792365         He          501    France    Male   44   \n",
       "9          10    15592389         H?          684    France    Male   27   \n",
       "10         11    15767821     Bearce          528    France    Male   31   \n",
       "11         12    15737173    Andrews          497     Spain    Male   24   \n",
       "12         13    15632264        Kay          476    France  Female   34   \n",
       "13         14    15691483       Chin          549    France  Female   25   \n",
       "14         15    15600882      Scott          635     Spain  Female   35   \n",
       "15         16    15643966    Goforth          616   Germany    Male   45   \n",
       "16         17    15737452      Romeo          653   Germany    Male   58   \n",
       "17         18    15788218  Henderson          549     Spain  Female   24   \n",
       "18         19    15661507    Muldrow          587     Spain    Male   45   \n",
       "19         20    15568982        Hao          726    France  Female   24   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2       0.00              1          1               1   \n",
       "1        1   83807.86              1          0               1   \n",
       "2        8  159660.80              3          1               0   \n",
       "3        1       0.00              2          0               0   \n",
       "4        2  125510.82              1          1               1   \n",
       "5        8  113755.78              2          1               0   \n",
       "6        7       0.00              2          1               1   \n",
       "7        4  115046.74              4          1               0   \n",
       "8        4  142051.07              2          0               1   \n",
       "9        2  134603.88              1          1               1   \n",
       "10       6  102016.72              2          0               0   \n",
       "11       3       0.00              2          1               0   \n",
       "12      10       0.00              2          1               0   \n",
       "13       5       0.00              2          0               0   \n",
       "14       7       0.00              2          1               1   \n",
       "15       3  143129.41              2          0               1   \n",
       "16       1  132602.88              1          1               0   \n",
       "17       9       0.00              2          1               1   \n",
       "18       6       0.00              1          0               0   \n",
       "19       6       0.00              2          1               1   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  \n",
       "5         149756.71       1  \n",
       "6          10062.80       0  \n",
       "7         119346.88       1  \n",
       "8          74940.50       0  \n",
       "9          71725.73       0  \n",
       "10         80181.12       0  \n",
       "11         76390.01       0  \n",
       "12         26260.98       0  \n",
       "13        190857.79       0  \n",
       "14         65951.65       0  \n",
       "15         64327.26       0  \n",
       "16          5097.67       1  \n",
       "17         14406.41       0  \n",
       "18        158684.81       0  \n",
       "19         54724.03       0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first 20 rows of dataset\n",
    "\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kda el details bt3t el customer htkon \n",
    "- RowNumber\n",
    "- CustomerId\n",
    "- Surname\n",
    "- CreditScore\n",
    "- Geography\n",
    "- Gender\n",
    "- Age\n",
    "- Tenure\n",
    "- Balance\n",
    "- NumOfProducts\n",
    "- HasCrCard\n",
    "- IsActiveMember\n",
    "- EstimatedSalary\n",
    "\n",
    "## w el output hikon\n",
    "- Exited\n",
    "\n",
    "## laken a7na hnst5dm f el classification \n",
    "- CreditScore\n",
    "- Geography\n",
    "- Gender\n",
    "- Age\n",
    "- Tenure\n",
    "- Balance\n",
    "- NumOfProducts\n",
    "- HasCrCard\n",
    "- IsActiveMember\n",
    "- EstimatedSalary\n",
    "- Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values #el output \"column exited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert Geograph column into scalar values\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "\n",
    "# Do same thing in Gender column\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [1]) #country\n",
    "X = onehotencoder.fit_transform(X).toarray() \n",
    "\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying features scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ...,\n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Initialize the artificial neural network\n",
    "classifier = Sequential()\n",
    "\n",
    "# Addi the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the artificial neural network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 7s 916us/step - loss: 0.4869 - acc: 0.7955\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 5s 657us/step - loss: 0.4297 - acc: 0.7960 1s -\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 5s 623us/step - loss: 0.4246 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4206 - acc: 0.817 - 5s 657us/step - loss: 0.4202 - acc: 0.8176\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 5s 659us/step - loss: 0.4174 - acc: 0.8262\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 5s 663us/step - loss: 0.4150 - acc: 0.8277\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 6s 716us/step - loss: 0.4140 - acc: 0.8301\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 6s 697us/step - loss: 0.4124 - acc: 0.8302\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 6s 701us/step - loss: 0.4111 - acc: 0.8329\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 5s 670us/step - loss: 0.4098 - acc: 0.8332\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 6s 701us/step - loss: 0.4091 - acc: 0.8346\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 6s 701us/step - loss: 0.4083 - acc: 0.8351\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 6s 709us/step - loss: 0.4078 - acc: 0.8340\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 6s 761us/step - loss: 0.4072 - acc: 0.8325\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 7s 820us/step - loss: 0.4065 - acc: 0.8346 5s - loss: 0.3761 - acc:  - ETA: 5s - los - ETA: 5\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 6s 706us/step - loss: 0.4060 - acc: 0.8345\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 6s 760us/step - loss: 0.4056 - acc: 0.8349\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 6s 800us/step - loss: 0.4051 - acc: 0.8334 0s - loss: \n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 7s 879us/step - loss: 0.4045 - acc: 0.8325\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 6s 740us/step - loss: 0.4042 - acc: 0.8349\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.4040 - acc: 0.8357\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 7s 903us/step - loss: 0.4031 - acc: 0.8345\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.4030 - acc: 0.8337\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 7s 841us/step - loss: 0.4027 - acc: 0.8342\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 7s 848us/step - loss: 0.4024 - acc: 0.8352 - ETA: 0s - loss: 0.40\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 6s 782us/step - loss: 0.4018 - acc: 0.8352 1s - loss: 0 - ETA: 0s - loss: 0.4055 - acc: 0 - ETA: 0s - loss: 0.4027 - acc: 0.83\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 6s 753us/step - loss: 0.4024 - acc: 0.8341 0s - loss: 0.4000 - acc: 0\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 6s 689us/step - loss: 0.4019 - acc: 0.8349\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 6s 747us/step - loss: 0.4020 - acc: 0.8346\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 5s 678us/step - loss: 0.4016 - acc: 0.8351\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 6s 701us/step - loss: 0.4020 - acc: 0.8351\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 5s 663us/step - loss: 0.4020 - acc: 0.8360\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 6s 693us/step - loss: 0.4012 - acc: 0.8345\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 5s 620us/step - loss: 0.4016 - acc: 0.8359\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.4016 - acc: 0.8355\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 6s 755us/step - loss: 0.4011 - acc: 0.8345\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 7s 852us/step - loss: 0.4010 - acc: 0.8336\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 7s 828us/step - loss: 0.4014 - acc: 0.8352\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 5s 665us/step - loss: 0.4010 - acc: 0.8344\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 7s 837us/step - loss: 0.4011 - acc: 0.8345\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4013 - acc: 0.8346\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 8s 947us/step - loss: 0.4006 - acc: 0.8346\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4011 - acc: 0.8347: 2\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4010 - acc: 0.8350: 7s - ETA: 1s - l\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4006 - acc: 0.8366: 0s - loss: 0.4014 - acc: 0.83 - ETA: 0s - loss: 0.4008 - acc: 0.837\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.4007 - acc: 0.8355: 6s - loss:  - ET\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4002 - acc: 0.8361\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4007 - acc: 0.8344\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 7s 908us/step - loss: 0.4003 - acc: 0.8361 4s - loss - ETA: 0s - loss: 0.4007 \n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 8s 946us/step - loss: 0.4002 - acc: 0.8339\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 8s 981us/step - loss: 0.4004 - acc: 0.8370\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 7s 829us/step - loss: 0.4000 - acc: 0.8351\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 7s 851us/step - loss: 0.4001 - acc: 0.8339 1\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4009 - acc: 0.8347\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3996 - acc: 0.8356: \n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3998 - acc: 0.8345\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4005 - acc: 0.8345\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4003 - acc: 0.8352\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3999 - acc: 0.8345\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3998 - acc: 0.8349: 4s - loss: 0.4087 - a - ETA: 4s - loss: 0.4083 - acc: 0. - ETA: 4s\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4005 - acc: 0.8350\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3997 - acc: 0.8351\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3998 - acc: 0.835 - 9s 1ms/step - loss: 0.3998 - acc: 0.8352\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 7s 841us/step - loss: 0.3997 - acc: 0.8346\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 7s 866us/step - loss: 0.4000 - acc: 0.8349 0s - loss: 0.4002 - a\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 8s 945us/step - loss: 0.3992 - acc: 0.8366 3s \n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4001 - acc: 0.8351\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 7s 881us/step - loss: 0.3998 - acc: 0.8347 6s - loss: 0.3 -\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 6s 749us/step - loss: 0.3998 - acc: 0.8351 0s - loss: 0.399\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 6s 733us/step - loss: 0.3999 - acc: 0.8350\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 6s 745us/step - loss: 0.3998 - acc: 0.8351\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 6s 719us/step - loss: 0.3998 - acc: 0.8345\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 7s 886us/step - loss: 0.3992 - acc: 0.8356\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 6s 746us/step - loss: 0.3998 - acc: 0.8360\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 6s 767us/step - loss: 0.3996 - acc: 0.8347\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.3996 - acc: 0.8374 1s - loss: \n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 6s 696us/step - loss: 0.3994 - acc: 0.8349\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 6s 794us/step - loss: 0.3999 - acc: 0.8350\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 7s 836us/step - loss: 0.3994 - acc: 0.8354\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 7s 880us/step - loss: 0.3992 - acc: 0.8344 1s - loss: 0.3 - ETA: 1s - loss: 0.\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 7s 937us/step - loss: 0.3997 - acc: 0.8352 0s - loss: 0.4024 -\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 6s 696us/step - loss: 0.3991 - acc: 0.8359 0s - loss: 0.3973 \n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 6s 794us/step - loss: 0.3997 - acc: 0.8344\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 6s 780us/step - loss: 0.3993 - acc: 0.8362\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.3995 - acc: 0.8345\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3996 - acc: 0.8361A: 0s - loss: 0.4004 - acc: 0\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3993 - acc: 0.8372A: 1s - loss: 0.399\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 6s 753us/step - loss: 0.3990 - acc: 0.8362\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 5s 665us/step - loss: 0.3992 - acc: 0.8364\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.3988 - acc: 0.8357\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 5s 684us/step - loss: 0.3991 - acc: 0.8367 1s - loss\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 6s 718us/step - loss: 0.3995 - acc: 0.8347\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 5s 686us/step - loss: 0.3993 - acc: 0.8379\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 5s 674us/step - loss: 0.3992 - acc: 0.8357\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 5s 674us/step - loss: 0.3995 - acc: 0.8360\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 5s 680us/step - loss: 0.3990 - acc: 0.8354\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 6s 704us/step - loss: 0.3990 - acc: 0.8359\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 5s 668us/step - loss: 0.3993 - acc: 0.8367\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 6s 717us/step - loss: 0.3994 - acc: 0.8361\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 6s 699us/step - loss: 0.3994 - acc: 0.8346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x271018b5630>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the artificial neural network to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1539,   56],\n",
       "       [ 255,  150]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acc of testing data is 84.45 %\n"
     ]
    }
   ],
   "source": [
    "print ('The acc of testing data is',((cm[0][0]+cm[1][1])*100)/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0]),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
